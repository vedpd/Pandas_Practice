{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stratascratch problems.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpQR4qBXLB5E2KgJVHNLd/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedpd/Pandas_Practice/blob/main/Stratascratch_problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.https://platform.stratascratch.com/coding/10285-acceptance-rate-by-date?python=1\n",
        "\n",
        "Acceptance Rate By Date\n",
        "What is the overall friend acceptance rate by date? Your output should have the rate of acceptances by the date the request was sent. Order by the earliest date to latest.\n",
        "\n",
        "Assume that each friend request starts by a user sending (i.e., user_id_sender) a friend request to another user (i.e., user_id_receiver) that's logged in the table with action = 'sent'. If the request is accepted, the table logs action = 'accepted'. If the request is not accepted, no record of action = 'accepted' is logged."
      ],
      "metadata": {
        "id": "rIDH8YjvSN9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCV0Hs0ISKh6"
      },
      "outputs": [],
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "#fb_friend_requests.head()\n",
        "\n",
        "#splitting data into sent and accepted\n",
        "fb_friend_sent = fb_friend_requests[fb_friend_requests.action==\"sent\"]\n",
        "fb_friend_accepted = fb_friend_requests[fb_friend_requests.action==\"accepted\"]\n",
        "\n",
        "#merging the data to bring sent and accepted in a single row for userid, received id combination\n",
        "merged_df = pd.merge(fb_friend_sent, fb_friend_accepted,  how='left', left_on=['user_id_sender','user_id_receiver'], right_on = ['user_id_sender','user_id_receiver'])\n",
        "\n",
        "\n",
        "#grouping the data based on the request sent\n",
        "grouped_df = merged_df.groupby(['date_x']).agg(['count'])#.reset_index()\n",
        "\n",
        "#converting the grouped data into dataframe\n",
        "grouped_df.columns = [ ' '.join(str(i) for i in col) for col in grouped_df.columns]\n",
        "grouped_df.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "#creating a new column in grouped data to find ratio between accepted/sent request\n",
        "grouped_df['acceptance_rate'] = grouped_df['action_y count']/grouped_df['action_x count']\n",
        "\n",
        "#subsetting columns to show date vs acceptance rate\n",
        "final_df = grouped_df[['date_x','acceptance_rate']]\n",
        "\n",
        "final_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.https://platform.stratascratch.com/coding/10064-highest-energy-consumption?python=1\n",
        "\n",
        "<b>Highest Energy Consumption</b> <br>\n",
        "Find the date with the highest total energy consumption from the Meta/Facebook data centers. Output the date along with the total energy consumption across all data centers. <br>\n",
        "DataFrames: fb_eu_energy, fb_asia_energy, fb_na_energy. <br>\n",
        "Expected Output Type: pandas.DataFrame"
      ],
      "metadata": {
        "id": "j6dB4Rw4iXQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "\n",
        "\n",
        "# using the approach to concatenate adding all dataframe along rows\n",
        "fb_final = pd.concat([fb_eu_energy,fb_asia_energy,fb_na_energy],axis=0)\n",
        "fb_grouped = fb_final.groupby(['date']).agg(['sum'])\n",
        "\n",
        "\n",
        "##converting the grouped data into dataframe\n",
        "fb_grouped.columns = [ ' '.join(str(i) for i in col) for col in fb_grouped.columns]\n",
        "fb_grouped.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "#obtaining max value of consumption\n",
        "max_cons = max(fb_grouped['consumption sum'])\n",
        "\n",
        "#subsetting based on max value of consumption\n",
        "fb_max_df = fb_grouped[fb_grouped['consumption sum'] == max_cons]"
      ],
      "metadata": {
        "id": "ekjwS8nviYkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.https://platform.stratascratch.com/coding/10322-finding-user-purchases?python=1\n",
        "\n",
        "<b>Finding User Purchases</b> <br>\n",
        "Write a query that'll identify returning active users. A returning active user is a user that has made a second purchase within 7 days of any other of their purchases. Output a list of user_ids of these returning active users."
      ],
      "metadata": {
        "id": "l4t-xQFVn9ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "amazon_transactions.head()\n",
        "\n",
        "#combine same dataframes using inner join\n",
        "amazon_combined = pd.merge(amazon_transactions, amazon_transactions, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "#above inner join gave duplicates- let's filter out the data\n",
        "amazon_combined['days'] = abs(amazon_combined['created_at_x'] - amazon_combined['created_at_y']).dt.days\n",
        "\n",
        "#because of abs value the difference can be negative and hence duplicates needs to be removed in last step\n",
        "\n",
        "#filtering data for days <=7 and ids not being same for 2 different items\n",
        "amazon_combined = amazon_combined[(amazon_combined.days <= 7) & (amazon_combined.id_x != amazon_combined.id_y)]\n",
        "\n",
        "#final list of user_id as due to absolute difference there will be duplicates\n",
        "\n",
        "values = amazon_combined['user_id'].drop_duplicates()"
      ],
      "metadata": {
        "id": "v3gLrJNHiZTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.https://platform.stratascratch.com/coding/10308-salaries-differences?python=1\n",
        "\n",
        "<b>Salaries Differences</b></br>\n",
        "Write a query that calculates the difference between the highest salaries found in the marketing and engineering departments. Output just the absolute difference in salaries."
      ],
      "metadata": {
        "id": "rAVwOWHNpTMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "#db_employee.head()\n",
        "\n",
        "#difference in salaries\n",
        "df_join = pd.merge(db_employee, db_dept, left_on=['department_id'], right_on=['id'], how='inner')\n",
        "\n",
        "result = df_join.groupby('department').agg('max')\n",
        "#print(result.head())\n",
        "\n",
        "mark_max= result.loc['marketing']['salary']\n",
        "eng_max = result.loc['engineering']['salary']\n",
        "\n",
        "diff = abs(mark_max-eng_max)"
      ],
      "metadata": {
        "id": "4qFK09WdpRgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.https://platform.stratascratch.com/coding/9913-order-details?python=1\n",
        "\n",
        "<b>Order Details</b></br>\n",
        "Find order details made by Jill and Eva.\n",
        "Consider the Jill and Eva as first names of customers.\n",
        "Output the order date, details and cost along with the first name. <br>\n",
        "Order records based on the customer id in ascending order.\n"
      ],
      "metadata": {
        "id": "4vG5thVIK2Dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "#customers.head()\n",
        "\n",
        "first_name_ls =['Jill','Eva']\n",
        "\n",
        "order_merged = pd.merge(customers,orders,left_on=\"id\", right_on = \"cust_id\", how = \"left\")\n",
        "\n",
        "#selecting specific columns\n",
        "order_merged_df = order_merged[['cust_id','first_name','order_date','order_details','total_order_cost']]\n",
        "\n",
        "#filtering data based on first_name\n",
        "order_merged_df = order_merged_df[order_merged_df['first_name'].isin(first_name_ls)]\n",
        "\n",
        "\n",
        "#sorting the final df\n",
        "order_merged_df.sort_values(by=['cust_id'],ascending=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbNO9WCXLAeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.https://platform.stratascratch.com/coding/10061-popularity-of-hack?python=1\n",
        "\n",
        "<b> Popularity of Hack </b> </br>\n",
        "Meta/Facebook has developed a new programing language called Hack.To measure the popularity of Hack they ran a survey with their employees. The survey included data on previous programing familiarity as well as the number of years of experience, age, gender and most importantly satisfaction with Hack. Due to an error location data was not collected, but your supervisor demands a report showing average popularity of Hack by office location. Luckily the user IDs of employees completing the surveys were stored.\n",
        "Based on the above, find the average popularity of the Hack per office location. <br><br>\n",
        "Output the location along with the average popularity."
      ],
      "metadata": {
        "id": "yBieDMikX06e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "#facebook_employees.head()\n",
        "\n",
        "fb_merged = pd.merge(facebook_hack_survey,facebook_employees,how=\"left\",left_on = \"employee_id\",right_on=\"id\")\n",
        "\n",
        "fb_grouped = fb_merged.groupby(['location'])['popularity'].mean().reset_index()\n",
        "\n",
        "fb_grouped.head()"
      ],
      "metadata": {
        "id": "_yY1Hg37X-tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.https://platform.stratascratch.com/coding/9917-average-salaries?python=1\n",
        "\n",
        "<b>Average Salaries</b></br>\n",
        "Compare each employee's salary with the average salary of the corresponding department.<br><br>\n",
        "Output the department, first name, and salary of employees along with the average salary of that department."
      ],
      "metadata": {
        "id": "qVZq6jZnnFhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "#employee.head()\n",
        "\n",
        "#creating average based on department\n",
        "dept_avg_df=employee.groupby([\"department\"])[\"salary\"].mean().reset_index().rename(columns={'salary':'avg_salary'})\n",
        "\n",
        "\n",
        "#merging with existing department dataframe\n",
        "merged_df = pd.merge(employee,dept_avg_df,how=\"left\",left_on=\"department\",right_on=\"department\")\n",
        "\n",
        "#selecting appropriate columns from dataframe\n",
        "merged_df = merged_df[['department','first_name','salary','avg_salary']]"
      ],
      "metadata": {
        "id": "h92dGUN4nMhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8.https://platform.stratascratch.com/coding/10060-top-cool-votes?python=1\n",
        "\n",
        "<b>Top Cool Votes</b><br>\n",
        "Find the review_text that received the highest number of  'cool' votes. <br><br>\n",
        "Output the business name along with the review text with the highest numbef of 'cool' votes."
      ],
      "metadata": {
        "id": "ghPPo797oMmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "yelp_reviews.head()\n",
        "\n",
        "max_cool = max(yelp_reviews['cool'])\n",
        "\n",
        "result_df = yelp_reviews[yelp_reviews['cool']==max_cool][['business_name','review_text']]"
      ],
      "metadata": {
        "id": "SLh2nQQ0oSJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.https://platform.stratascratch.com/coding/10087-find-all-posts-which-were-reacted-to-with-a-heart?python=1\n",
        "\n",
        "<b>Find all posts which were reacted to with a heart</b><br><br>\n",
        "Find all posts which were reacted to with a heart."
      ],
      "metadata": {
        "id": "okOlx8qDr_TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "facebook_reactions.head()\n",
        "\n",
        "merged_df= pd.merge(facebook_posts,facebook_reactions,how=\"inner\",left_on='post_id',right_on='post_id').reset_index()\n",
        "\n",
        "#selecting final list of columns and renaming one column\n",
        "result_df = merged_df[merged_df['reaction']=='heart'][['post_id','poster_x','post_text','post_keywords','post_date']].rename(columns={'poster_x':'poster'})\n",
        "\n",
        "#post filtering removing duplicate post id as multiple users might have given heart on same post id - we need distinct post id for such cases\n",
        "\n",
        "final_df= result_df.drop_duplicates(keep=\"first\")"
      ],
      "metadata": {
        "id": "JW8T5exIr_xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.https://platform.stratascratch.com/coding/10156-number-of-units-per-nationality?python=1\n",
        "\n",
        "<b>Number Of Units Per Nationality</b> <br>\n",
        "Find the number of apartments per nationality that are owned by people under 30 years old. <br> <br>\n",
        "Output the nationality along with the number of apartments.\n",
        "Sort records by the apartments count in descending order."
      ],
      "metadata": {
        "id": "GpW6ashr1KXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "#airbnb_hosts.head()\n",
        "\n",
        "#airbnb_units.head()\n",
        "merged_df = pd.merge(airbnb_hosts,airbnb_units,how='inner', left_on ='host_id', right_on = 'host_id')\n",
        "\n",
        "merged_df_new = merged_df[(merged_df['age']<30) & (merged_df['unit_type']=='Apartment')]\n",
        "\n",
        "merged_df_new.head()\n",
        "\n",
        "grouped_df = merged_df_new.groupby(['nationality'])[['unit_id']].nunique().reset_index().sort_values(by='unit_id',ascending=False)\n"
      ],
      "metadata": {
        "id": "sQncbwju1QeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11.https://platform.stratascratch.com/coding/9688-churro-activity-date?python=1\n",
        "\n",
        "<b>Churro Activity Date</b> <br><br>\n",
        "Find the activity date and the pe_description of facilities with the name 'STREET CHURROS' and with a score of less than 95 points.\n"
      ],
      "metadata": {
        "id": "UIe1FdWh3lge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "los_angeles_restaurant_health_inspections.head()\n",
        "\n",
        "#filtering the data\n",
        "result = los_angeles_restaurant_health_inspections[(los_angeles_restaurant_health_inspections['score']< 95)]\n",
        "    \n",
        "result = result[result['facility_name']=='STREET CHURROS']\n",
        "\n",
        "#selecting specific columns from filtered data\n",
        "result=result[['activity_date','pe_description']]\n",
        "\n",
        "#converting to expected date time\n",
        "result['activity_date'] = result['activity_date'].dt.date\n",
        "\n",
        "#checking the results\n",
        "result.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "bL046tqf3rN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12.https://platform.stratascratch.com/coding/10003-lyft-driver-wages?python=1\n",
        "\n",
        "<b>Lyft Driver Wages</b> <br>\n",
        "Find all Lyft drivers who earn either equal to or less than 30k USD or equal to or more than 70k USD. <br> <br>\n",
        "Output all details related to retrieved records."
      ],
      "metadata": {
        "id": "1Dxr_G5F5Z1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "lyft_drivers.head()\n",
        "\n",
        "#filtering the data\n",
        "lyft_drivers[(lyft_drivers['yearly_salary'] <= 30000) | (lyft_drivers['yearly_salary'] >= 70000)]\n"
      ],
      "metadata": {
        "id": "JxemPcvp5hKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13.https://platform.stratascratch.com/coding/9991-top-ranked-songs?python=1\n",
        "\n",
        "<b>Top Ranked Songs</b> <br>\n",
        "Find songs that have ranked in the top position. Output the track name and the number of times it ranked at the top. <br><br>Sort your records by the number of times the song was in the top position in descending order.\n"
      ],
      "metadata": {
        "id": "_OhB373S8ljp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "spotify_worldwide_daily_song_ranking.head()\n",
        "\n",
        "result_df = spotify_worldwide_daily_song_ranking[spotify_worldwide_daily_song_ranking['position']==1]\n",
        "\n",
        "#grouping the data,getting the column with number of times track came\n",
        "# counting the cases,resetting index, renaming column as expected \n",
        "# and then sorting the values in descending order\n",
        "grouped_df = result_df.groupby(['trackname'])['position'].count().reset_index().rename(columns={'position':'times_top1'}).sort_values(by='times_top1',ascending=False)"
      ],
      "metadata": {
        "id": "sr3U8jHU8hPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14.https://platform.stratascratch.com/coding/10078-find-matching-hosts-and-guests-in-a-way-that-they-are-both-of-the-same-gender-and-nationality?python=1\n",
        "\n",
        "<b>Find matching hosts and guests in a way that they are both of the same gender and nationality</b><br>\n",
        "Find matching hosts and guests pairs in a way that they are both of the same gender and nationality.<br><br>\n",
        "Output the host id and the guest id of matched pair."
      ],
      "metadata": {
        "id": "XwamzGzO_rKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "#airbnb_hosts.head()\n",
        "#airbnb_guests.head()\n",
        "\n",
        "merged_df = pd.merge(airbnb_hosts,airbnb_guests, how=\"left\",left_on=['nationality','gender'],right_on=['nationality','gender'])\n",
        "\n",
        "#post left join dropping the duplicates\n",
        "result_df=merged_df[['host_id','guest_id']].drop_duplicates()"
      ],
      "metadata": {
        "id": "_oSfErR3_zIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15.https://platform.stratascratch.com/coding/9992-find-artists-that-have-been-on-spotify-the-most-number-of-times?python=1\n",
        "\n",
        "<b>Find how many times each artist appeared on the Spotify ranking list</b><br>\n",
        "Find how many times each artist appeared on the Spotify ranking list<br><br>\n",
        "Output the artist name along with the corresponding number of occurrences.<br>\n",
        "Order records by the number of occurrences in descending order."
      ],
      "metadata": {
        "id": "9tbb7ZbCBH9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "spotify_worldwide_daily_song_ranking.head()\n",
        "\n",
        "#grouping,counting, sorting and renaming\n",
        "grouped_df = spotify_worldwide_daily_song_ranking.groupby(['artist'])['id'].count().reset_index().sort_values(by='id',ascending=False).rename(columns={'id':'n_occurences'})"
      ],
      "metadata": {
        "id": "S7IMQUw0BPY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16.https://platform.stratascratch.com/coding/10128-count-the-number-of-movies-that-abigail-breslin-nominated-for-oscar?python=1\n",
        "\n",
        "<b>Count the number of movies that Abigail Breslin nominated for oscar</b><br><br>\n",
        "Count the number of movies that Abigail Breslin was nominated for an oscar."
      ],
      "metadata": {
        "id": "V0Y__cXFCZzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "oscar_nominees.head()\n",
        "\n",
        "#filtering the data\n",
        "result_df=oscar_nominees[oscar_nominees['nominee']=='Abigail Breslin']\n",
        "\n",
        "#finding total such entries\n",
        "len(result_df)"
      ],
      "metadata": {
        "id": "sURdsIDNCZCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17.https://platform.stratascratch.com/coding/9972-find-the-base-pay-for-police-captains?python=1\n",
        "\n",
        "<b>Find the base pay for Police Captains</b><br>\n",
        "Find the base pay for Police Captains.<br><br>\n",
        "Output the employee name along with the corresponding base pay.\n",
        "\n",
        "<i> Hint: Use str.contains()- by selecting a series from the pandas dataframe\n"
      ],
      "metadata": {
        "id": "qIJqHSTQElzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "sf_public_salaries.head()\n",
        "\n",
        "#using contains function to get cases where jobtitle has captain\n",
        "result_df = sf_public_salaries.loc[sf_public_salaries['jobtitle'].str.contains('Captain',case= False)]\n",
        "\n",
        "result_df[['employeename','basepay']]"
      ],
      "metadata": {
        "id": "fx84iIcXEnKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18.https://platform.stratascratch.com/coding/9924-find-libraries-who-havent-provided-the-email-address-in-2016-but-their-notice-preference-definition-is-set-to-email?python=1\n",
        "\n",
        "<b>Find libraries who haven't provided the email address in circulation year 2016 but their notice preference definition is set to email</b><br>\n",
        "Find libraries who haven't provided the email address in circulation year 2016 but their notice preference definition is set to email.<br><br>\n",
        "Output the library code."
      ],
      "metadata": {
        "id": "m1YuQN8MGuGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "library_usage.head()\n",
        "\n",
        "#filtering with and condition\n",
        "#selecting only home_library_code\n",
        "#removing any duplicates\n",
        "library_usage[(library_usage['circulation_active_year']==2016) &    (library_usage['notice_preference_definition']== \"email\") & (library_usage['provided_email_address']== False)][['home_library_code']].drop_duplicates()"
      ],
      "metadata": {
        "id": "408AHS4iGswS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19.https://platform.stratascratch.com/coding/9663-find-the-most-profitable-company-in-the-financial-sector-of-the-entire-world-along-with-its-continent?python=1\n",
        "\n",
        "<b>Find the most profitable company in the financial sector of the entire world along with its continent</b><br>\n",
        "Find the most profitable company from the financial sector.<br><br> Output the result along with the continent.\n",
        "<br> <i><b> Hint: Use nlargest(number_of_larges_items,column based on which highest is to be picked)</b></i>"
      ],
      "metadata": {
        "id": "9emkQljRIjCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "forbes_global_2010_2014.head()\n",
        "\n",
        "#using nlargest to get largest 1 value based on profit\n",
        "#getting respective columns accordingly\n",
        "forbes_global_2010_2014[forbes_global_2010_2014['sector']=='Financials'].nlargest(1,\"profits\")[['company','continent']]"
      ],
      "metadata": {
        "id": "6OGUfMk2Isd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20.https://platform.stratascratch.com/coding/9650-find-the-top-10-ranked-songs-in-2010?python=1\n",
        "\n",
        "<b>Find the top 10 ranked songs in 2010</b><br>\n",
        "What were the top 10 ranked songs in 2010? <br><br>\n",
        "Output the rank, group name, and song name but do not show the same song twice.<br>\n",
        "Sort the result based on the year_rank in ascending order."
      ],
      "metadata": {
        "id": "4C-di7DALo3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "billboard_top_100_year_end.head()\n",
        "\n",
        "df= billboard_top_100_year_end\n",
        "\n",
        "#filtering the data\n",
        "#selecting columns\n",
        "#removing duplicates\n",
        "df[(df['year']==2010) & (df['year_rank']<=10)][['year_rank','group_name','song_name']].drop_duplicates()"
      ],
      "metadata": {
        "id": "ygCFcOw8LyiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21.https://platform.stratascratch.com/coding/9942-largest-olympics?python=1\n",
        "\n",
        "<b>Largest Olympics</b><br>\n",
        "Find the Olympics with the highest number of athletes. The Olympics game is a combination of the year and the season, and is found in the 'games' column. <br><br>Output the Olympics along with the corresponding number of athletes."
      ],
      "metadata": {
        "id": "S5k2UwyHOd6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Approach : 1\n",
        "\n",
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "olympics_athletes_events.head()\n",
        "\n",
        "#grouping the data\n",
        "#reindexing\n",
        "#renaming columns\n",
        "grouped_df = olympics_athletes_events.groupby(['games'])['id'].nunique().reset_index().rename(columns={'id':'athletes_count'})\n",
        "\n",
        "#identifying max athlete value\n",
        "max_athletes = max(grouped_df['athletes_count'])\n",
        "\n",
        "#generating output\n",
        "grouped_df[grouped_df['athletes_count'] == max_athletes]\n"
      ],
      "metadata": {
        "id": "0V1t21sMOmSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Approach:2\n",
        "\n",
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "df = olympics_athletes_events.copy()\n",
        "df.groupby('games')['id'].nunique().reset_index().nlargest(1, 'id').rename(columns={'id':'athletes_count'})"
      ],
      "metadata": {
        "id": "7y-nHV8YOru4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22.https://platform.stratascratch.com/coding/10176-bikes-last-used?python=1\n",
        "\n",
        "<b>Bikes Last Used</b>br>\n",
        "Find the last time each bike was in use. Output both the bike number and the date-timestamp of the bike's last use (i.e., the date-time the bike was returned). <br><br>Order the results by bikes that were most recently used.\n",
        "\n",
        "<b><i>Hint: drop the bikes having multiple entries once the data has been sorted in decreasing order, use : drop_duplicates(subset='bike_number')</b></i>"
      ],
      "metadata": {
        "id": "Qs-FuDKvSVCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Start writing code\n",
        "dc_bikeshare_q1_2012.head()\n",
        "\n",
        "#sort data based on end time in descending order\n",
        "# same bike can have multiple end time, latest end time would be at top\n",
        "# remove duplicate cases for such bikes\n",
        "# take out necessary columns\n",
        "# rename last column\n",
        "dc_bikeshare_q1_2012.sort_values(by='end_time',ascending=False).drop_duplicates(subset='bike_number')\n",
        "\\[['bike_number','end_time']].rename(columns={'end_time':'last_used'})"
      ],
      "metadata": {
        "id": "zNLF7EbSSS1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}